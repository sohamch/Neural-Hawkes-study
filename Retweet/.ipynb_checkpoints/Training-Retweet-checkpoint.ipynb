{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EzZlMyBh-Z6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from LSTM_construction import CTLSTM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TQanVxBh-aJ"
   },
   "source": [
    "# First, we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68RvwFrsh-aK"
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"RetweetTrainData.h5\", \"r\") as fl:\n",
    "    EventsData = np.array(fl[\"EventsData\"])\n",
    "    timesData = np.array(fl[\"TimesData\"])\n",
    "    timeMaxData = np.array(fl[\"TimeMaxData\"])\n",
    "    SeqLengthData = np.array(fl[\"SeqLengthData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjJVGp2nh-aL"
   },
   "outputs": [],
   "source": [
    "# Make one-hot encoded events\n",
    "# Make the events one hot encoded\n",
    "N_train = EventsData.shape[0]\n",
    "N_seq_Max = EventsData.shape[1]\n",
    "N_types = 3\n",
    "Events_one_hot = np.zeros((N_train, N_seq_Max, N_types))\n",
    "for seq in range(N_train):\n",
    "    for step in range(SeqLengthData[seq]):\n",
    "        ev = EventsData[seq, step]\n",
    "        Events_one_hot[seq, step, ev] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFNQ00W0h-aM",
    "outputId": "61f21c62-f58a-4d7b-f9ac-bbba52ffea78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604798.0"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(timeMaxData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_xx2Ulhh-aN"
   },
   "outputs": [],
   "source": [
    "# Then convert everything to torch tensors\n",
    "# Since maximum times are very large here,\n",
    "# we scale them down so that gradients don't explode\n",
    "# This doesn't affect final results, since we can always\n",
    "# scale testing times by the same amount too\n",
    "timeScale = 1.0\n",
    "EvTens = pt.tensor(Events_one_hot).double()\n",
    "EvIndTens = pt.tensor(EventsData).long()\n",
    "timeTensor = pt.tensor(timesData/timeScale).double()\n",
    "tMaxTensor = pt.tensor(timeMaxData/timeScale).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndKGPYuzh-aP"
   },
   "outputs": [],
   "source": [
    "assert pt.all(timeTensor[:, 0]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeaT9oN-h-aQ"
   },
   "outputs": [],
   "source": [
    "# Then produce the mask\n",
    "mask = EvIndTens.ge(-1+0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89mN3jBfh-aQ"
   },
   "source": [
    "# Now, we make the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeEyapQkh-aR",
    "outputId": "e3351419-2469-4cbd-ec83-c8cc51db9852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:48<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:36<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:42<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:42<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:36<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:40<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:41<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:38<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:37<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:36<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:37<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:32<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:34<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:32<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:33<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:35<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:32<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:35<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:32<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:34<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:35<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:33<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [10:55<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [11:33<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [11:40<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 400/400 [11:37<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create the network\n",
    "reload = True # Set to False if starting from scratch\n",
    "if reload: # load the last saved network\n",
    "    N_saved_last = 21 # this has to be changed when we reload from a certain time index\n",
    "    try:\n",
    "        net = pt.load('RetweetNets/TrainNet_{}ep.pt'.format(N_saved_last))\n",
    "    except:\n",
    "        print(\"No saved network found. Starting from scratch\")\n",
    "        N_saved_last = 0\n",
    "        net = CTLSTM(K=N_types, hD=64).double()\n",
    "        \n",
    "else : #initiazlize from scratch\n",
    "    N_saved_last = 0\n",
    "    net = CTLSTM(K=N_types, hD=64).double()\n",
    "\n",
    "N_train = 4000\n",
    "N_epoch = 50 - N_saved_last\n",
    "BatchSize = 10\n",
    "# Initiate Adam optimizer\n",
    "optimizer = pt.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# start training\n",
    "for epoch in range(N_epoch):\n",
    "    \n",
    "    print(\"Epoch:{}\".format(epoch+N_saved_last), flush=True)\n",
    "    \n",
    "    # Checkpoint\n",
    "    pt.save(net, 'RetweetNets/TrainNet_{}ep.pt'.format(epoch+N_saved_last))\n",
    "    \n",
    "    # permutation for this epoch\n",
    "    perm = pt.randperm(N_train)\n",
    "    for batchInd in tqdm(range(0, N_train, BatchSize), position=0, leave=True):\n",
    "        # Gather the necessary inputs\n",
    "        BatchEventsHot = EvTens[perm][batchInd:batchInd+BatchSize]\n",
    "        BatchEventsInd = EvIndTens[perm][batchInd:batchInd+BatchSize]\n",
    "        BatchTimes = timeTensor[perm][batchInd:batchInd+BatchSize]\n",
    "        BatchTMax = tMaxTensor[perm][batchInd:batchInd+BatchSize]\n",
    "        BatchMask = mask[perm][batchInd:batchInd+BatchSize]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do the forward pass\n",
    "        lambOuts, CLows, Cbars, deltas, OutGates = net.forward(BatchEventsHot, BatchMask, BatchTimes)\n",
    "        # Calculate the MC loss\n",
    "        LMC, trandsLMC, t_upLMC = net.MC_Loss(BatchTimes, BatchTMax,\n",
    "                                      CLows, Cbars, deltas, OutGates,\n",
    "                                      Nsamples=N_seq_Max)\n",
    "        # Calculate the likelihood\n",
    "        LogLikeLoss = net.logLoss(BatchEventsInd, BatchMask, lambOuts)\n",
    "        \n",
    "        loss = LogLikeLoss + LMC\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3vQdl5jh-aS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdhG9Ab3h-aT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training-Retweet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
