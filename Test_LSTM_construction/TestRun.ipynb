{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from LSTM_construction import CTLSTM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "try:\n",
    "    Events = np.load(\"Events.npy\")\n",
    "    Times = np.load(\"Times.npy\")\n",
    "    Mu = np.load(\"Mu.npy\")\n",
    "    alpha = np.load(\"alpha.npy\")\n",
    "    delta = np.load(\"Delta.npy\")\n",
    "except:\n",
    "    raise FileNotFoundError(\"Required files not found. Please Run the SE_MPP-synthetic notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 50), (100, 51))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Events.shape, Times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a random mask to simulate variable lengths of the sequences\n",
    "mask = pt.ones(Events.shape[0], Events.shape[1], dtype=pt.int8)\n",
    "# Now let's assign some random lengths to them - minimum length 10 (just a choice)\n",
    "SeqLens = pt.zeros(Events.shape[0]).int()\n",
    "tMax = pt.zeros(Events.shape[0])\n",
    "for i in range(mask.shape[0]):\n",
    "    rn = np.random.randint(10, Events.shape[1])\n",
    "    SeqLens[i] = rn\n",
    "    tMax[i] = Times[i, rn]\n",
    "    mask[i, rn:] = 0\n",
    "\n",
    "mask = mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the events one hot encoded\n",
    "Events_one_hot = np.zeros((Events.shape[0], Events.shape[1], 5))\n",
    "for seq in range(Events.shape[0]):\n",
    "    for step in range(Events.shape[1]):\n",
    "        ev = Events[seq, step]\n",
    "        Events_one_hot[seq, step, ev] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, convert everything to tensors\n",
    "EvTens = pt.tensor(Events_one_hot)\n",
    "EvIndTens = pt.tensor(Events)\n",
    "timeTensor = pt.tensor(Times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network - 5 event types - 64 x 64 matrix\n",
    "net = CTLSTM(K=5, hD=64).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the network for a minibatch of 10 samples\n",
    "N_batch = 10\n",
    "EvBatch = EvTens[:N_batch].double()\n",
    "maskBatch = mask[:N_batch]\n",
    "EvIndBatch = EvIndTens[:N_batch].long()\n",
    "timeBatch = timeTensor[:N_batch].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 5]), torch.Size([10, 51]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvBatch.shape, timeBatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 1. Do the forward pass\n",
    "lambOuts, CLows, Cbars, deltas, OutGates = net.forward(EvBatch, maskBatch, timeBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# 2. Do the MC Integration\n",
    "# The function returns all the random times and\n",
    "# sorting indices that were used so that we can\n",
    "# test for correctness\n",
    "# times, tMax, Clows, Cbars, deltas, OutGates, Nsamples=1000\n",
    "LMC, trandsLMC, t_upLMC = net.MC_Loss(timeBatch, tMax[:N_batch], CLows, Cbars, deltas, OutGates, Nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluate the log likelihood\n",
    "LogLikeLoss = net.logLoss(EvIndBatch, maskBatch, lambOuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We test the three components - log-likelihood calculation, MC integration and forward pass\n",
    "\n",
    "## First, the log likelihood - the easiest one\n",
    "## Goal is to go through each sequence individually and check if our batch processing results, done with advanced indexing match with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the log likelihood loss\n",
    "loss_total = 0\n",
    "\n",
    "# Go through each sequence\n",
    "for i in range(N_batch):\n",
    "    # Get the events that occurred in this sequence\n",
    "    seq = Events[i][mask[i]]\n",
    "    loss_seq = 0.\n",
    "    # Go through the events\n",
    "    for evInd in range(seq.shape[0]):\n",
    "        # Get the event type (0, 1, 2, 3 or 4)\n",
    "        ev = seq[evInd]\n",
    "        # Add the log of the intensity of the event type\n",
    "        # to the log-likelihood of the current sequence\n",
    "        lamb = lambOuts[i, evInd, ev]\n",
    "        loss_seq += pt.log(lamb)\n",
    "    # Add the log-likelihood of this sequence\n",
    "    # to the total log-likelihood of the batch\n",
    "    loss_total -= loss_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood part correct\n"
     ]
    }
   ],
   "source": [
    "# Check if the results match with batch processing results\n",
    "assert pt.allclose(loss_total/N_batch, LogLikeLoss)\n",
    "print(\"Log likelihood part correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, the MC integration part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the indices for upper time limit\n",
    "t_up = pt.searchsorted(timeBatch, trandsLMC)\n",
    "assert pt.equal(t_up, t_upLMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 500])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trandsLMC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we'll evaluate the integral individually for each sequence\n",
    "\n",
    "# Get the no. of random time samples that were drawn\n",
    "Nsamples = trandsLMC.shape[1]\n",
    "lamb_total = 0.\n",
    "# Go through each sequence\n",
    "for i in range(N_batch):\n",
    "    # Get the times for this sequence\n",
    "    times_seq = timeBatch[i, :SeqLens[i] + 1]\n",
    "    # Go through the randomly selected times\n",
    "    lamb_tot_seq = 0.\n",
    "    for sample in range(Nsamples):\n",
    "        t_drawn = trandsLMC[i, sample]\n",
    "        # Get the index of this times\n",
    "        idx = pt.searchsorted(times_seq, t_drawn)\n",
    "        # Check if the index is correct\n",
    "        assert idx == t_up[i, sample]\n",
    "        \n",
    "        # Next, we need to evaluate the total rate at this time\n",
    "        # To do this, we need the LSTM values for this time stamp\n",
    "        tlow = times_seq[idx - 1]\n",
    "        clow = CLows[i, idx - 1]\n",
    "        cbar = Cbars[i, idx - 1]\n",
    "        o = OutGates[i, idx - 1]\n",
    "        delta = deltas[i, idx - 1]\n",
    "        \n",
    "        # We then compute c(t)\n",
    "        ct = cbar + (clow - cbar)*pt.exp(-(t_drawn - tlow)*delta)\n",
    "        \n",
    "        # Then h(t)\n",
    "        ht = o * (2*net.sigma(2*ct) - 1)\n",
    "        \n",
    "        # Then lambda_tilde\n",
    "        lamb_til = net.L_lamb_til(ht)\n",
    "        \n",
    "        # Then lambda\n",
    "        # evaluate this element-wise too - good for checking correctness\n",
    "        lamb = pt.zeros(5)\n",
    "        for k in range(5):\n",
    "            s_k = net.scale[k]\n",
    "            lamb[k] = s_k * pt.log(1 + pt.exp(lamb_til[k] / s_k))\n",
    "        \n",
    "        # Add the total intensity at this random time to the total for this sequence\n",
    "        lamb_tot_seq += pt.sum(lamb)\n",
    "    \n",
    "    # Add the lambda*End_time for this sequence to the total\n",
    "    lamb_total += lamb_tot_seq*times_seq[-1]/Nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC integral result correct\n"
     ]
    }
   ],
   "source": [
    "assert pt.allclose(lamb_total/N_batch, LMC.double())\n",
    "print(\"MC integral result correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what we have till now is that if the forward pass is correct, then the Log-likelihhod and Monte Carlo integral estimation are also correct.\n",
    "## So, Third, now we confirm that the forward pass is correct.\n",
    "## As before, we'll do the forward pass explicitly sample by sample and confirm that our results match with the batch processing results of the neural network which uses advanced pytorch indexing for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass sample by sample and step by step checks complete\n"
     ]
    }
   ],
   "source": [
    "# Let's do the forward pass sample by sample.\n",
    "N_events = Events.shape[1]\n",
    "hD = net.hD\n",
    "\n",
    "for seq in range(N_batch):\n",
    "    # Get the on-hot encoded sequence\n",
    "    Events_seq = EvBatch[seq, :SeqLens[seq]]\n",
    "    times_seq = timeBatch[seq, :SeqLens[seq] + 1]\n",
    "    \n",
    "    # Initialize ht, ct and cbar to zero\n",
    "    ht = pt.zeros(hD).double()\n",
    "    ct = pt.zeros(hD).double()\n",
    "    cbar = pt.zeros(hD).double()\n",
    "    # Now go through this sequence\n",
    "    for evInd in range(SeqLens[seq]):\n",
    "        \n",
    "        # Get the one-hot encoded event\n",
    "        event = Events_seq[evInd]\n",
    "        # get the linear output\n",
    "        Linout = net.L_U(event) + net.L_V(ht)\n",
    "        \n",
    "        # get the non linear outputs\n",
    "        i, f = net.sigma(Linout[:hD]), net.sigma(Linout[hD:2*hD])\n",
    "            \n",
    "        iBar, fBar = net.sigma(Linout[2*hD:3*hD]), net.sigma(Linout[3*hD:4*hD])\n",
    "\n",
    "        # Remember to multiply \"z\" by 2\n",
    "        z, o = 2*net.sigma(Linout[4*hD:5*hD]), net.sigma(Linout[5*hD:6*hD])\n",
    "\n",
    "        delta = F.softplus(Linout[6*hD:7*hD])\n",
    "        \n",
    "        clow = f * ct + i * z\n",
    "        cbar = fBar * cbar + iBar * z\n",
    "        \n",
    "        \n",
    "        tnow = times_seq[evInd]\n",
    "        tnext = times_seq[evInd + 1]\n",
    "        \n",
    "        ct = cbar + (clow - cbar)*pt.exp(-(tnext - tnow)*delta)\n",
    "        \n",
    "        ht = o * (2*net.sigma(2*ct) - 1)\n",
    "        \n",
    "        lamb_til = net.L_lamb_til(ht)\n",
    "        \n",
    "        lamb = pt.zeros(5).double()\n",
    "        for k in range(5):\n",
    "            s_k = net.scale[k]\n",
    "            lamb[k] = s_k * pt.log(1 + pt.exp(lamb_til[k] / s_k))\n",
    "        \n",
    "        # Now check correctness\n",
    "        assert pt.allclose(delta, deltas[seq, evInd]), \"{} {}\".format(seq, evInd)\n",
    "        assert pt.allclose(clow, CLows[seq, evInd]), \"{} {}\".format(seq, evInd)\n",
    "        assert pt.allclose(cbar, Cbars[seq, evInd]), \"{} {}\".format(seq, evInd)\n",
    "        assert pt.allclose(o, OutGates[seq, evInd]), \"{} {}\".format(seq, evInd)\n",
    "        assert pt.allclose(lamb, lambOuts[seq, evInd]), \"{} {}\".format(seq, evInd)\n",
    "        \n",
    "print(\"Forward pass sample by sample and step by step checks complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
