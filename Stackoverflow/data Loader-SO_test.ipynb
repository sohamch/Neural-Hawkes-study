{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"data Loader-SO_test.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ArYew7p_rCp7"},"source":["import pickle\n","import numpy as np\n","import torch as pt\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KitmbkEvrCqE"},"source":["# First, Let's load the data"]},{"cell_type":"code","metadata":{"id":"tOXLP593rCqF"},"source":["with open(\"test_SO.pkl\", \"rb\") as f:\n","    dat = pickle.load(f, encoding='bytes')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gmh89_1krCqG"},"source":["test = dat[b'test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvwH_Nx4rCqG"},"source":["# lMax = 0\n","# for i in range(len(train)):\n","#     if len(train[i]) > lMax:\n","#         lMax = len(train[i])\n","\n","# For the stack overflow data set, we truncate each sequence to length 250 max\n","# So that we can finish training in manageable time\n","lMax = 250"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_Y9_oWvrCqG"},"source":["# Now, let's store everything in Numpy arrays"]},{"cell_type":"code","metadata":{"id":"jsoJ094ArCqH"},"source":["EventsData = np.ones((len(test), lMax), dtype=int)\n","timesData = np.zeros((len(test), lMax+1))\n","timeMaxData = np.zeros(len(test))\n","SeqLengthData = np.zeros(len(test), dtype=int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ilT2V54rCqH","outputId":"d9a2df0e-e49b-4702-a447-b81105082f77"},"source":["print(\"Starting Data Processing\", flush=True)\n","for seq in tqdm(range(len(test)), position=0, leave=True):\n","    if len(test[seq]) > lMax:\n","        Up = lMax\n","    else:\n","        Up = len(test[seq])\n","        \n","    for step in range(0, Up):\n","        dct = test[seq][step]\n","        event_type = dct[b'type_event']\n","        time = dct[b'time_since_start']\n","        \n","        EventsData[seq, step] = event_type\n","        timesData[seq, step+1] = time # the first will be stored as zero\n","    \n","    timeMaxData[seq] = timesData[seq, step+1] # the max interval of this sequence\n","    SeqLengthData[seq] = Up\n","    \n","    # Now let's fill up remaining events with -1 indicating no event occured\n","    # and the times with increasing values so that sorting order is not changed\n","    inc = 0\n","    for step in range(Up, lMax):\n","        EventsData[seq, step] = -1\n","        \n","        # keep increasing the time so that sorting order is unaffected\n","        # will help in searching for intervals of random times in MC simulation\n","        inc += 1\n","        timesData[seq, step+1] = timeMaxData[seq] + inc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Starting Data Processing\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1326/1326 [00:00<00:00, 5243.82it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WsRDvnGCrCqJ"},"source":["# Now save the arrays into an hdf5 file\n","# This makes it easier for handling later\n","import h5py\n","with h5py.File(\"SOTestData.h5\", \"w\") as fl:\n","    fl.create_dataset(\"EventsData\", data = EventsData)\n","    fl.create_dataset(\"TimesData\", data = timesData)\n","    fl.create_dataset(\"TimeMaxData\", data = timeMaxData)\n","    fl.create_dataset(\"SeqLengthData\", data = SeqLengthData)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbuRhnrnrCqJ"},"source":[""],"execution_count":null,"outputs":[]}]}